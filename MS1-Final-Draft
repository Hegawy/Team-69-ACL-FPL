{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6380645,"sourceType":"datasetVersion","datasetId":3677153}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras import Sequential, Input\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.metrics import Precision, Recall\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:12:03.128523Z","iopub.execute_input":"2025-10-22T16:12:03.128875Z","iopub.status.idle":"2025-10-22T16:12:03.135247Z","shell.execute_reply.started":"2025-10-22T16:12:03.128851Z","shell.execute_reply":"2025-10-22T16:12:03.134228Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/fantasy-football/cleaned_merged_seasons.csv')\n\n# Normalize positions (GKP -> GK)\nposition_col = next((c for c in df.columns if c.lower() in (\"position\",\"pos\",\"element_type\",\"player_position\")), None)\nif position_col:\n    df[position_col] = df[position_col].astype(str).str.upper().replace({\"GKP\":\"GK\"})\n    print(\"Position values:\", df[position_col].unique()[:20])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:12:03.138663Z","iopub.execute_input":"2025-10-22T16:12:03.139024Z","iopub.status.idle":"2025-10-22T16:12:03.651195Z","shell.execute_reply.started":"2025-10-22T16:12:03.138998Z","shell.execute_reply":"2025-10-22T16:12:03.650048Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Fill team_x as the PLAYER'S TEAM using opponent-of-opponent within (season, fixture) ===\n# Assumes a DataFrame named `df` is already in memory.\n\nimport pandas as pd\nimport numpy as np\n\n# --- Auto-detect columns ---\nseason_col = next((c for c in df.columns if \"season\" in c.lower()), None)\nfix_col    = next((c for c in df.columns if c.lower() in [\"gw\",\"gameweek\",\"round\",\"event\",\"fixture\"]), None)\n\n# prefer an opponent NAME column (string/object)\nopp_name_col = None\nfor c in df.columns:\n    cl = c.lower()\n    if (\"opp\" in cl or \"opponent\" in cl) and (df[c].dtype == object):\n        opp_name_col = c\n        break\n\nteam_x_col = \"team_x\" if \"team_x\" in df.columns else next((c for c in df.columns if c.lower() == \"team\"), None)\nif team_x_col is None:\n    team_x_col = \"team_x\"\n    df[team_x_col] = np.nan\n\n# --- Opponent-of-opponent mapping per (season, fixture) ---\ndef _norm(x):\n    if pd.isna(x): return x\n    return str(x).strip()\n\nfilled_recip = 0\nif all([season_col, fix_col, opp_name_col, team_x_col]):\n    sub = df[[season_col, fix_col, opp_name_col]].dropna().copy()\n    sub[\"_opp_norm\"] = sub[opp_name_col].map(_norm)\n\n    pair_map = {}  # {(season, fixture): {opp_name -> other_opp_name}}\n    for (s, f), grp in sub.groupby([season_col, fix_col], dropna=False):\n        uniq = list(grp[\"_opp_norm\"].dropna().unique())\n        if len(uniq) == 2:\n            a, b = uniq[0], uniq[1]\n            pair_map[(s, f)] = {a: b, b: a}\n        elif len(uniq) > 2:\n            # fallback: take the two most frequent\n            counts = grp[\"_opp_norm\"].value_counts()\n            top = list(counts.index[:2])\n            if len(top) == 2:\n                pair_map[(s, f)] = {top[0]: top[1], top[1]: top[0]}\n\n    before_nulls = df[team_x_col].isna().sum()\n\n    def infer_team_x(row):\n        if pd.notna(row.get(team_x_col)):\n            return row[team_x_col]\n        key = (row.get(season_col), row.get(fix_col))\n        opp = _norm(row.get(opp_name_col))\n        return pair_map.get(key, {}).get(opp, np.nan)\n\n    df[team_x_col] = df.apply(infer_team_x, axis=1)\n    filled_recip = int(before_nulls - df[team_x_col].isna().sum())\n# ============================================================================================\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:12:03.653099Z","iopub.execute_input":"2025-10-22T16:12:03.653394Z","iopub.status.idle":"2025-10-22T16:12:05.042341Z","shell.execute_reply.started":"2025-10-22T16:12:03.653373Z","shell.execute_reply":"2025-10-22T16:12:05.041211Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Changing Column Names\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# Ensure was_home is boolean-like (handles 1/0, True/False, \"True\"/\"False\")\nif df[\"was_home\"].dtype != bool:\n    df[\"was_home\"] = df[\"was_home\"].map({\n        True: True, False: False,\n        1: True, 0: False,\n        \"True\": True, \"False\": False\n    }).fillna(df[\"was_home\"])\n    if df[\"was_home\"].dtype != bool:\n        df[\"was_home\"] = df[\"was_home\"].astype(int).astype(bool)\n\n# Build the two new columns as integers\ndf[\"player_team_score\"] = np.where(df[\"was_home\"], df[\"team_h_score\"], df[\"team_a_score\"]).astype(int)\ndf[\"opp_team_score\"] = np.where(df[\"was_home\"], df[\"team_a_score\"], df[\"team_h_score\"]).astype(int)\n\n# âœ… Convert was_home to integers (1 = home, 0 = away)\ndf[\"was_home\"] = df[\"was_home\"].astype(int)\ndf = df.drop(columns=['team_h_score', 'team_a_score'], errors='ignore')\n\n\n\ndf.info()\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:12:05.043205Z","iopub.execute_input":"2025-10-22T16:12:05.043474Z","iopub.status.idle":"2025-10-22T16:12:05.130528Z","shell.execute_reply.started":"2025-10-22T16:12:05.043448Z","shell.execute_reply":"2025-10-22T16:12:05.129427Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = df.drop(columns=['transfers_in', 'transfers_out'], errors='ignore')\n\ndf.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:12:05.13267Z","iopub.execute_input":"2025-10-22T16:12:05.133016Z","iopub.status.idle":"2025-10-22T16:12:05.194806Z","shell.execute_reply.started":"2025-10-22T16:12:05.132991Z","shell.execute_reply":"2025-10-22T16:12:05.193995Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"position_encoded = pd.get_dummies(df['position'], prefix='pos')\n\n# Concatenate back to df and drop the original column\ndf = pd.concat([df.drop(columns=['position']), position_encoded], axis=1)\n\ndf.info()\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:12:05.195768Z","iopub.execute_input":"2025-10-22T16:12:05.196122Z","iopub.status.idle":"2025-10-22T16:12:05.313881Z","shell.execute_reply.started":"2025-10-22T16:12:05.1961Z","shell.execute_reply":"2025-10-22T16:12:05.312774Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pos_cols = [c for c in df.columns if c.startswith('pos_')]\n\n# Convert them to int\ndf[pos_cols] = df[pos_cols].astype(int)\n\n\ndf.info()\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:12:05.315091Z","iopub.execute_input":"2025-10-22T16:12:05.31542Z","iopub.status.idle":"2025-10-22T16:12:05.376159Z","shell.execute_reply.started":"2025-10-22T16:12:05.315392Z","shell.execute_reply":"2025-10-22T16:12:05.374907Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Calculating Form\n### As the average total points over the past four gameweeks (if available), divided by 10","metadata":{}},{"cell_type":"code","source":"# Sort properly\ndf = df.sort_values(by=[\"name\", \"season_x\", \"GW\"])\n\n# Compute the average total points over the previous 4 GWs (divided by 10)\ndf[\"form\"] = (\n    df.groupby([\"name\", \"season_x\"], group_keys=False)\n      .apply(lambda g: g.assign(\n          form=(g[\"total_points\"]\n                .shift(1)                                   # exclude current GW\n                .rolling(window=4, min_periods=1)           # up to 4 previous GWs\n                .mean() / 10)\n      ))\n      [\"form\"]\n)\n\n# Replace NaN (first GW of each season) with 0\ndf[\"form\"] = df[\"form\"].fillna(0)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:12:05.377321Z","iopub.execute_input":"2025-10-22T16:12:05.37767Z","iopub.status.idle":"2025-10-22T16:12:08.72832Z","shell.execute_reply.started":"2025-10-22T16:12:05.377638Z","shell.execute_reply":"2025-10-22T16:12:08.727277Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:12:08.729347Z","iopub.execute_input":"2025-10-22T16:12:08.729584Z","iopub.status.idle":"2025-10-22T16:12:08.75009Z","shell.execute_reply.started":"2025-10-22T16:12:08.729565Z","shell.execute_reply":"2025-10-22T16:12:08.749068Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.a \n### 3rd --> TODO Average total points for each position for each season\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n\n# One-hot position columns in your df\npos_cols = ['pos_DEF', 'pos_FWD', 'pos_GK', 'pos_MID']\n\n# Melt to long form (one row per player-position)\nmelted = df.melt(\n    id_vars=['season_x', 'total_points'],\n    value_vars=pos_cols,\n    var_name='position',\n    value_name='is_pos'\n)\n\n# Keep only rows where the player is that position\nmelted = melted[melted['is_pos'] == 1].copy()\nmelted['position'] = melted['position'].str.replace('pos_', '', regex=False)\n\n# (Optional) nicer labels\npos_label_map = {'DEF': 'Defender', 'FWD': 'Forward', 'GK': 'Goalkeeper', 'MID': 'Midfielder'}\nmelted['position'] = melted['position'].map(pos_label_map).fillna(melted['position'])\n\n# ---- Step 1: Sum points by season & position (seasonal totals per position)\nseason_pos_sum = (\n    melted.groupby(['season_x', 'position'], as_index=False)['total_points']\n          .sum()\n          .rename(columns={'total_points': 'season_sum_points'})\n)\n\n# ---- Step 2: Average those seasonal sums across seasons (answer to the question)\navg_seasonal_sum = (\n    season_pos_sum.groupby('position', as_index=False)['season_sum_points']\n                  .mean()\n                  .rename(columns={'season_sum_points': 'avg_season_sum_points'})\n                  .sort_values('avg_season_sum_points', ascending=False)\n)\n\n# ============================\n# Diagram 1: Seasonal sums per position (grouped bars by season)\n# ============================\npivot = season_pos_sum.pivot(index='season_x', columns='position', values='season_sum_points').fillna(0)\npivot = pivot.sort_index()\n\nseasons = pivot.index.astype(str).tolist()\npositions = pivot.columns.tolist()\nn_pos = len(positions)\nx = np.arange(len(seasons))\nbar_width = 0.8 / max(n_pos, 1)\n\nplt.figure(figsize=(12, 6))\nfor i, pos in enumerate(positions):\n    y = pivot[pos].values\n    plt.bar(x + i*bar_width - (n_pos-1)*bar_width/2, y, width=bar_width, label=pos)\n\nplt.title('Seasonal Sum of Total Points per Position')\nplt.xlabel('Season')\nplt.ylabel('Sum of Total Points (per season)')\nplt.xticks(x, seasons)\nplt.legend(title='Position')\nplt.tight_layout()\nplt.show()\n\n# ============================\n# Diagram 2: Average seasonal sum across seasons (the answer)\n# ============================\nplt.figure(figsize=(8, 5))\nplt.bar(avg_seasonal_sum['position'], avg_seasonal_sum['avg_season_sum_points'])\nplt.title('Average Seasonal Sum of Total Points by Position')\nplt.xlabel('Position')\nplt.ylabel('Average Seasonal Sum of Total Points')\nplt.tight_layout()\nplt.show()\n\n# Optional: print numeric result\n# display(avg_seasonal_sum)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:12:08.751058Z","iopub.execute_input":"2025-10-22T16:12:08.751306Z","iopub.status.idle":"2025-10-22T16:12:09.328815Z","shell.execute_reply.started":"2025-10-22T16:12:08.751287Z","shell.execute_reply":"2025-10-22T16:12:09.327863Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.b","metadata":{}},{"cell_type":"markdown","source":"### Form Evolution","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Select the desired season\nseason_2023 = df[df['season_x'] == '2022-23'].copy()\n\n# Identify top 5 players by total points that season\ntop5_total = (\n    season_2023.groupby('name')['total_points']\n    .sum()\n    .sort_values(ascending=False)\n    .head(5)\n    .index\n)\n\n# Plot form evolution for those players\nplt.figure(figsize=(12, 6))\n\nfor player in top5_total:\n    player_data = (\n        season_2023.loc[season_2023['name'] == player, ['GW', 'form']]\n        .fillna(0)  # ðŸ‘ˆ include GW1 (form = 0 by definition)\n        .sort_values('GW')\n    )\n    if not player_data.empty:\n        plt.plot(player_data['GW'], player_data['form'], marker='o', label=player)\n\nplt.title('Form Evolution of Top 5 Total-Point Players (2022â€“23)')\nplt.xlabel('Gameweek')\nplt.ylabel('Form (average of previous 4 GWs Ã· 10)')\nplt.grid(True, linestyle='--', alpha=0.5)\nplt.legend(title='Player', bbox_to_anchor=(1.02, 1), loc='upper left')\nplt.tight_layout()\nplt.show()\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:12:09.331651Z","iopub.execute_input":"2025-10-22T16:12:09.331972Z","iopub.status.idle":"2025-10-22T16:12:09.711083Z","shell.execute_reply.started":"2025-10-22T16:12:09.331945Z","shell.execute_reply":"2025-10-22T16:12:09.709981Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### The top players in form VS the top players with the highest total points","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\n# Filter season\nseason_2023 = df[df['season_x'] == '2022-23'].copy()\n\n# â”€â”€ Top 5 players by total points â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ntop5_total = (\n    season_2023.groupby('name')['total_points']\n    .sum()\n    .sort_values(ascending=False)\n    .head(5)\n)\n\n# â”€â”€ Top 5 players by highest form (peak form) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ntop5_form_peak = (\n    season_2023.groupby('name')['form']\n    .max()\n    .sort_values(ascending=False)\n    .head(5)\n)\n\n# â”€â”€ Plot side-by-side figures â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# --- Chart 1 : Total Points ---\nsns.barplot(\n    x=top5_total.values, y=top5_total.index,\n    ax=axes[0], palette='Blues_r'\n)\naxes[0].set_title('Top 5 Players by Total Points (2022â€“23)')\naxes[0].set_xlabel('Total Points')\naxes[0].set_ylabel('Player')\naxes[0].grid(True, axis='x', linestyle='--', alpha=0.4)\n\n# --- Chart 2 : Highest Form ---\nsns.barplot(\n    x=top5_form_peak.values, y=top5_form_peak.index,\n    ax=axes[1], palette='Greens_r'\n)\naxes[1].set_title('Top 5 Players by Highest Form (2022â€“23)')\naxes[1].set_xlabel('Highest Form (Peak)')\naxes[1].set_ylabel('Player')\naxes[1].grid(True, axis='x', linestyle='--', alpha=0.4)\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:12:09.712169Z","iopub.execute_input":"2025-10-22T16:12:09.712449Z","iopub.status.idle":"2025-10-22T16:12:10.143837Z","shell.execute_reply.started":"2025-10-22T16:12:09.712427Z","shell.execute_reply":"2025-10-22T16:12:10.142698Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Part 3","metadata":{}},{"cell_type":"markdown","source":"## Downloading CSV","metadata":{}},{"cell_type":"code","source":"df.to_csv('updated_dataset.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:12:10.14495Z","iopub.execute_input":"2025-10-22T16:12:10.145271Z","iopub.status.idle":"2025-10-22T16:12:11.468479Z","shell.execute_reply.started":"2025-10-22T16:12:10.145247Z","shell.execute_reply":"2025-10-22T16:12:11.467021Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Load your dataset\ndf = pd.read_csv(\"/kaggle/working/updated_dataset.csv\")\n\n# Sort properly by player and week\ndf = df.sort_values(by=[\"name\", \"season_x\", \"GW\"])\n\n# Create upcoming_total_points = next weekâ€™s total_points per player\ndf[\"upcoming_total_points\"] = (\n    df.groupby([\"name\", \"season_x\"])[\"total_points\"].shift(-1)\n)\n\n# Drop rows without upcoming_total_points (last GW per player)\ndf = df.dropna(subset=[\"upcoming_total_points\"]).reset_index(drop=True)\n\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:12:11.469624Z","iopub.execute_input":"2025-10-22T16:12:11.469907Z","iopub.status.idle":"2025-10-22T16:12:11.919751Z","shell.execute_reply.started":"2025-10-22T16:12:11.469884Z","shell.execute_reply":"2025-10-22T16:12:11.918441Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Selecting Important Features","metadata":{}},{"cell_type":"code","source":"## put 4 at the bottom here in order","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:12:11.920809Z","iopub.execute_input":"2025-10-22T16:12:11.921289Z","iopub.status.idle":"2025-10-22T16:12:11.92567Z","shell.execute_reply.started":"2025-10-22T16:12:11.921264Z","shell.execute_reply":"2025-10-22T16:12:11.924628Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Model And SHAP Lime**","metadata":{}},{"cell_type":"code","source":"import numpy as np, pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\n\n\nmatch_features = [\n    \"minutes\",\"goals_scored\",\"assists\",\"clean_sheets\",\n    \"goals_conceded\",\"saves\",\"bonus\",\"influence\",\n    \"creativity\",\"threat\",\"player_team_score\",\"opp_team_score\"\n]\nplayer_features = [\"form\",\"value\",\"pos_DEF\",\"pos_MID\",\"pos_FWD\",\"pos_GK\"]\nfeatures = [c for c in (match_features+player_features) if c in df.columns]\nif \"pos_GK\" in features: features.remove(\"pos_GK\")  # avoid dummy trap\n\nX = df[features].astype(float).values\ny = df[\"upcoming_total_points\"].astype(float).values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nscaler = StandardScaler()\nX_train_s = scaler.fit_transform(X_train)\nX_test_s  = scaler.transform(X_test)\n\n# Linear Regression\nlr = LinearRegression().fit(X_train_s, y_train)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:12:11.926692Z","iopub.execute_input":"2025-10-22T16:12:11.927535Z","iopub.status.idle":"2025-10-22T16:12:12.073395Z","shell.execute_reply.started":"2025-10-22T16:12:11.927502Z","shell.execute_reply":"2025-10-22T16:12:12.072606Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# âœ… Add right after Cell 16 (end of the cell)\n\n# Define relevant features per position\nposition_feature_map = {\n    \"FWD\": [\"minutes\",\"goals_scored\",\"assists\",\"bonus\",\"influence\",\"creativity\",\"threat\",\"form\",\"value\"],\n    \"MID\": [\"minutes\",\"goals_scored\",\"assists\",\"clean_sheets\",\"bonus\",\"influence\",\"creativity\",\"threat\",\"form\",\"value\"],\n    \"DEF\": [\"minutes\",\"clean_sheets\",\"goals_conceded\",\"bonus\",\"influence\",\"threat\",\"form\",\"value\"],\n    \"GK\":  [\"minutes\",\"clean_sheets\",\"goals_conceded\",\"saves\",\"bonus\",\"form\",\"value\"]\n}\n\n# Helper function to detect player position for a given test index\ndef get_position_from_row(row):\n    if row[df.columns.get_loc(\"pos_FWD\")] == 1: return \"FWD\"\n    if row[df.columns.get_loc(\"pos_MID\")] == 1: return \"MID\"\n    if row[df.columns.get_loc(\"pos_DEF\")] == 1: return \"DEF\"\n    return \"GK\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:12:12.074101Z","iopub.execute_input":"2025-10-22T16:12:12.074365Z","iopub.status.idle":"2025-10-22T16:12:12.085711Z","shell.execute_reply.started":"2025-10-22T16:12:12.074342Z","shell.execute_reply":"2025-10-22T16:12:12.083452Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shap\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Fix SHAP compatibility\nif not hasattr(np, \"bool\"): np.bool = bool\nif not hasattr(np, \"str\"):  np.str  = str\n\n# We'll rebuild a mapping from X_test rows back to df:\n# This only works if X_train/X_test were split from df[features] in the same order.\ndf_features_only = df[features].values\n\n# Find matching df row for each X_test row\ntest_df_indices = []\nfor x in X_test:\n    # locate first matching row\n    match_idx = np.where((df_features_only == x).all(axis=1))[0]\n    test_df_indices.append(match_idx[0] if len(match_idx) > 0 else None)\n\n# SHAP per position\nfor pos in position_feature_map.keys():\n\n    print(f\"\\n===================== ðŸ“Œ SHAP Global Summary for {pos} =====================\")\n\n    # Filter test rows for this position\n    pos_test_indices = []\n    for i, df_idx in enumerate(test_df_indices):\n        if df_idx is not None:\n            orig_row = df.iloc[df_idx]\n            if get_position_from_row(orig_row) == pos:\n                pos_test_indices.append(i)\n\n    if len(pos_test_indices) == 0:\n        print(f\"No test samples for position {pos}, skipping.\")\n        continue\n\n    X_test_pos = X_test_s[pos_test_indices]\n\n    # Background = train (same for all positions, or we can filter later)\n    bg_idx = np.random.RandomState(42).choice(len(X_train_s), size=min(1000, len(X_train_s)), replace=False)\n    background_pos = X_train_s[bg_idx]\n\n    explainer_pos = shap.LinearExplainer(lr, background_pos)\n    shap_vals_pos = explainer_pos(X_test_pos)\n\n    valid_features = [f for f in position_feature_map[pos] if f in features]\n    feature_indices = [features.index(f) for f in valid_features]\n\n    filtered_shap = shap_vals_pos.values[:, feature_indices]\n    filtered_Xtest = X_test_pos[:, feature_indices]\n\n    shap.summary_plot(filtered_shap, filtered_Xtest, feature_names=valid_features)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:12:12.087046Z","iopub.execute_input":"2025-10-22T16:12:12.087393Z","iopub.status.idle":"2025-10-22T16:13:32.546638Z","shell.execute_reply.started":"2025-10-22T16:12:12.087369Z","shell.execute_reply":"2025-10-22T16:13:32.545555Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import shap, numpy as np, matplotlib.pyplot as plt\n# # fix numpy deprecations some SHAP versions expect\n# if not hasattr(np, \"bool\"): np.bool = bool\n# if not hasattr(np, \"str\"):  np.str  = str\n\n# # background sample\n# bg_idx = np.random.RandomState(42).choice(len(X_train_s), size=min(1000, len(X_train_s)), replace=False)\n# background_lr = X_train_s[bg_idx]\n\n# explainer_lr = shap.LinearExplainer(lr, background_lr)\n# shap_vals_lr = explainer_lr(X_test_s)\n\n# # Summary (global importance)\n# plt.figure(figsize=(10,6))\n# shap.summary_plot(shap_vals_lr, X_test_s, feature_names=features, show=False)\n# plt.tight_layout(); plt.show()\n\n# # Force plot (single instance)\n# i = 0\n# plt.figure(figsize=(10,2.7))\n# shap.force_plot(\n#     explainer_lr.expected_value,\n#     shap_vals_lr.values[i,:],\n#     X_test_s[i,:],\n#     feature_names=features,\n#     matplotlib=True,\n#     show=False\n# )\n# plt.show()\n\n\n\nimport shap, numpy as np, matplotlib.pyplot as plt\n# # fix numpy deprecations some SHAP versions expect\nif not hasattr(np, \"bool\"): np.bool = bool\nif not hasattr(np, \"str\"):  np.str  = str\n\n# # background sample\n# bg_idx = np.random.RandomState(42).choice(len(X_train_s), size=min(1000, len(X_train_s)), replace=False)\n# background_lr = X_train_s[bg_idx]\n\n# explainer_lr = shap.LinearExplainer(lr, background_lr)\n# shap_vals_lr = explainer_lr(X_test_s)\n\n\n\n\n\n\n# âœ… Choose instance index\ni = 0\n\n# âœ… Get player position from original dataset row\noriginal_idx = df.iloc[X_test.argmax(axis=1)[i]] if hasattr(X_test, \"argmax\") else df.iloc[i]\n# Alternatively, safer:\npos = None\nfor idx, row in df.iterrows():\n    if np.array_equal(row[features].values, X_test[i]):\n        pos = get_position_from_row(row.values)\n        break\n\n# âœ… If not found directly (rare case), fallback:\nif pos is None:\n    pos = \"FWD\"\n\n# âœ… Get valid features for position\nvalid_features = [f for f in position_feature_map[pos] if f in features]\nfeature_indices = [features.index(f) for f in valid_features]\n\n# âœ… Filter SHAP and X_test\nfiltered_shap = shap_vals_lr.values[:, feature_indices]\nfiltered_Xtest = X_test_s[:, feature_indices]\n\n# âœ… SHAP Summary (only relevant features)\nplt.figure(figsize=(10,6))\nshap.summary_plot(filtered_shap, filtered_Xtest, feature_names=valid_features, show=False)\nplt.tight_layout(); plt.show()\n\n# âœ… SHAP Force plot\nplt.figure(figsize=(10,2.7))\nshap.force_plot(\n    explainer_lr.expected_value,\n    filtered_shap[i,:],\n    filtered_Xtest[i,:],\n    feature_names=valid_features,\n    matplotlib=True,\n    show=False\n)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:13:32.547831Z","iopub.execute_input":"2025-10-22T16:13:32.548198Z","iopub.status.idle":"2025-10-22T16:14:06.902353Z","shell.execute_reply.started":"2025-10-22T16:13:32.548169Z","shell.execute_reply":"2025-10-22T16:14:06.901087Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import tensorflow as tf\n# from tensorflow import keras\n# from tensorflow.keras import layers\n# tf.keras.utils.set_random_seed(42)\n\n# ffnn = keras.Sequential([\n#     layers.Input(shape=(X_train_s.shape[1],)),\n#     layers.Dense(64, activation=\"relu\"),\n#     layers.Dropout(0.1),\n#     layers.Dense(32, activation=\"relu\"),\n#     layers.Dense(1),\n# ])\n# ffnn.compile(optimizer=keras.optimizers.Adam(1e-3), loss=\"mae\", metrics=[keras.metrics.MAE])\n# ffnn.fit(X_train_s, y_train, validation_split=0.1, epochs=50, batch_size=256, verbose=0)\n\n# # SHAP KernelExplainer (subset for speed)\n# pred_fn = lambda arr: ffnn.predict(arr, verbose=0).reshape(-1)\n# bg = X_train_s[np.random.RandomState(42).choice(len(X_train_s), size=min(200, len(X_train_s)), replace=False)]\n# ke = shap.KernelExplainer(pred_fn, bg)\n# samp_idx = np.random.RandomState(7).choice(len(X_test_s), size=min(200, len(X_test_s)), replace=False)\n# X_samp = X_test_s[samp_idx]\n# shap_vals_ff = ke.shap_values(X_samp, nsamples=100)\n\n# # Summary\n# plt.figure(figsize=(10,6))\n# shap.summary_plot(shap_vals_ff, X_samp, feature_names=features, show=False)\n# plt.tight_layout(); plt.show()\n\n# # Force plot for one instance\n# plt.figure(figsize=(10,2.7))\n# shap.force_plot(ke.expected_value, shap_vals_ff[0,:], X_samp[0,:], feature_names=features, matplotlib=True, show=False)\n# plt.show()\n\n\n\n\n\n\n\n\n# import tensorflow as tf\n# from tensorflow import keras\n# from tensorflow.keras import layers\n# tf.keras.utils.set_random_seed(42)\n\n# # âœ… Early stopping callback\n# early_stop = tf.keras.callbacks.EarlyStopping(\n#     monitor='val_loss',  # watches validation loss\n#     patience=6,          # stops if no improvement for 5 epochs\n#     restore_best_weights=True # goes back to best model state\n# )\n\n# ffnn = keras.Sequential([\n#     layers.Input(shape=(X_train_s.shape[1],)),\n#     layers.Dense(64, activation=\"relu\"),\n#     layers.Dropout(0.1),\n#     layers.Dense(32, activation=\"relu\"),\n#     layers.Dense(1),\n# ])\n\n# ffnn.compile(\n#     optimizer=keras.optimizers.Adam(1e-3),\n#     loss=\"mae\",\n#     metrics=[keras.metrics.MAE]\n# )\n\n# # âœ… Added callback here\n# ffnn.fit(\n#     X_train_s, y_train,\n#     validation_split=0.1,\n#     epochs=50,\n#     batch_size=256,\n#     callbacks=[early_stop],\n#     verbose=0\n# )\n\n# # SHAP KernelExplainer (subset for speed)\n# pred_fn = lambda arr: ffnn.predict(arr, verbose=0).reshape(-1)\n# bg = X_train_s[np.random.RandomState(42).choice(len(X_train_s), size=min(200, len(X_train_s)), replace=False)]\n# ke = shap.KernelExplainer(pred_fn, bg)\n# samp_idx = np.random.RandomState(7).choice(len(X_test_s), size=min(200, len(X_test_s)), replace=False)\n# X_samp = X_test_s[samp_idx]\n# shap_vals_ff = ke.shap_values(X_samp, nsamples=100)\n\n# # Summary\n# plt.figure(figsize=(10,6))\n# shap.summary_plot(shap_vals_ff, X_samp, feature_names=features, show=False)\n# plt.tight_layout(); plt.show()\n\n# # Force plot for one instance\n# plt.figure(figsize=(10,2.7))\n# shap.force_plot(ke.expected_value, shap_vals_ff[0,:], X_samp[0,:], feature_names=features, matplotlib=True, show=False)\n# plt.show()\n\n\n\n\n\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\ntf.keras.utils.set_random_seed(42)\n\nearly_stop = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=6,\n    restore_best_weights=True\n)\n\nffnn = keras.Sequential([\n    layers.Input(shape=(X_train_s.shape[1],)),\n    layers.Dense(64, activation=\"relu\"),\n    layers.Dropout(0.1),\n    layers.Dense(32, activation=\"relu\"),\n    layers.Dense(1),\n])\n\nffnn.compile(optimizer=keras.optimizers.Adam(1e-3), loss=\"mae\", metrics=[keras.metrics.MAE])\nffnn.fit(X_train_s, y_train, validation_split=0.1, epochs=50, batch_size=256, callbacks=[early_stop], verbose=0)\n\n# SHAP KernelExplainer\npred_fn = lambda arr: ffnn.predict(arr, verbose=0).reshape(-1)\nbg = X_train_s[np.random.RandomState(42).choice(len(X_train_s), size=min(200, len(X_train_s)), replace=False)]\nke = shap.KernelExplainer(pred_fn, bg)\nsamp_idx = np.random.RandomState(7).choice(len(X_test_s), size=min(200, len(X_test_s)), replace=False)\nX_samp = X_test_s[samp_idx]\nshap_vals_ff = ke.shap_values(X_samp, nsamples=100)\n\n# âœ… Choose test example\ni = 0\n\n# âœ… Get position and valid features\npos = get_position_from_row(df.iloc[X_test.argmax(axis=1)[i]] if hasattr(X_test, \"argmax\") else df.iloc[i])\nvalid_features = [f for f in position_feature_map[pos] if f in features]\nfeature_indices = [features.index(f) for f in valid_features]\n\n# âœ… Filter SHAP and X_samp\nfiltered_shap_ff = shap_vals_ff[:, feature_indices]\nfiltered_Xsamp = X_samp[:, feature_indices]\n\n# âœ… SHAP Summary\nplt.figure(figsize=(10,6))\nshap.summary_plot(filtered_shap_ff, filtered_Xsamp, feature_names=valid_features, show=False)\nplt.tight_layout(); plt.show()\n\n# âœ… SHAP Force plot for instance 0\nplt.figure(figsize=(10,2.7))\nshap.force_plot(ke.expected_value, filtered_shap_ff[0,:], filtered_Xsamp[0,:], feature_names=valid_features, matplotlib=True, show=False)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:14:06.903584Z","iopub.execute_input":"2025-10-22T16:14:06.903881Z","iopub.status.idle":"2025-10-22T16:18:35.165136Z","shell.execute_reply.started":"2025-10-22T16:14:06.903858Z","shell.execute_reply":"2025-10-22T16:18:35.164163Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import lime.lime_tabular\n# # LR -> wrapper on unscaled input so LIME can sample around raw features\n# def lr_predict_raw(x_raw):\n#     return lr.predict(scaler.transform(x_raw))\n\n# explainer_lime = lime.lime_tabular.LimeTabularExplainer(\n#     training_data=X_train, feature_names=features,\n#     discretize_continuous=True, mode='regression', random_state=42\n# )\n\n# i = 0\n# exp_lr = explainer_lime.explain_instance(X_test[i], lr_predict_raw, num_features=min(10,len(features)))\n# fig = exp_lr.as_pyplot_figure(); plt.show()\n\n# # FFNN wrapper\n# def ffnn_predict_raw(x_raw):\n#     return ffnn.predict(scaler.transform(x_raw), verbose=0).reshape(-1)\n\n# j = 1\n# exp_ff = explainer_lime.explain_instance(X_test[j], ffnn_predict_raw, num_features=min(10,len(features)))\n# fig = exp_ff.as_pyplot_figure(); plt.show()\n\n\n\n\n# import lime.lime_tabular\n\n# def lr_predict_raw(x_raw):\n#     return lr.predict(scaler.transform(x_raw))\n\n# explainer_lime = lime.lime_tabular.LimeTabularExplainer(\n#     training_data=X_train, feature_names=features,\n#     discretize_continuous=True, mode='regression', random_state=42\n# )\n\n# explainer_lime_pos = lime.lime_tabular.LimeTabularExplainer(\n#     training_data=X_train[:, feature_indices],\n#     feature_names=valid_features,\n#     discretize_continuous=True,\n#     mode='regression',\n#     random_state=42\n# )\n# # âœ… Choose test index\n# i = 0\n\n# # âœ… Get position and relevant features\n# pos = get_position_from_row(df.iloc[X_test.argmax(axis=1)[i]] if hasattr(X_test, \"argmax\") else df.iloc[i])\n# valid_features = [f for f in position_feature_map[pos] if f in features]\n# feature_indices = [features.index(f) for f in valid_features]\n\n# # âœ… FFNN wrapper\n# def ffnn_predict_raw(x_raw):\n#     return ffnn.predict(scaler.transform(x_raw), verbose=0).reshape(-1)\n\n# # âœ… LIME - Linear Regression\n# exp_lr = explainer_lime_pos.explain_instance(X_test[i][feature_indices], lr_predict_raw, num_features=len(valid_features))\n# fig = exp_lr.as_pyplot_figure(); plt.show()\n\n# # âœ… LIME - FFNN\n# j = 1\n# exp_ff = explainer_lime_pos.explain_instance(X_test[j][feature_indices], ffnn_predict_raw, num_features=len(valid_features))\n# fig = exp_ff.as_pyplot_figure(); plt.show()\n\n\n\n\n\n\nimport lime.lime_tabular\nimport numpy as np\n\n# Helper: takes reduced x_raw (pos-only) â†’ rebuilds full-length input\ndef rebuild_full_input(x_raw_subset, feature_indices, full_dim=len(features)):\n    full_input = np.zeros((x_raw_subset.shape[0], full_dim))\n    full_input[:, feature_indices] = x_raw_subset\n    return full_input\n\n# âœ… Full prediction wrapper for LR\ndef lr_predict_pos(x_raw_subset):\n    full_input = rebuild_full_input(x_raw_subset, feature_indices)\n    return lr.predict(scaler.transform(full_input))\n\n# âœ… Full prediction wrapper for FFNN\ndef ffnn_predict_pos(x_raw_subset):\n    full_input = rebuild_full_input(x_raw_subset, feature_indices)\n    return ffnn.predict(scaler.transform(full_input), verbose=0).reshape(-1)\n\n# âœ… Select index to explain\ni = 0\n\n# âœ… Detect player position from df\npos = get_position_from_row(df.iloc[i])\nprint(pos)\n\n# âœ… Filter valid features for that position\nvalid_features = [f for f in position_feature_map[pos] if f in features]\nfeature_indices = [features.index(f) for f in valid_features]\n\n# âœ… Create a position-specific explainer\nexplainer_lime_pos = lime.lime_tabular.LimeTabularExplainer(\n    training_data=X_train_s[:, feature_indices],\n    feature_names=valid_features,\n    discretize_continuous=True,\n    mode='regression',\n    random_state=42\n)\n\n# âœ… Explain LR\nexp_lr = explainer_lime_pos.explain_instance(\n    X_test_s[i][feature_indices],\n    lr_predict_pos,\n    num_features=len(valid_features)\n)\nfig = exp_lr.as_pyplot_figure(); plt.show()\n\n# âœ… Explain FFNN (using a different test sample)\nj = 1\nexp_ff = explainer_lime_pos.explain_instance(\n    X_test_s[j][feature_indices],\n    ffnn_predict_pos,\n    num_features=len(valid_features)\n)\nfig = exp_ff.as_pyplot_figure(); plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:18:35.166273Z","iopub.execute_input":"2025-10-22T16:18:35.166608Z","iopub.status.idle":"2025-10-22T16:18:36.109687Z","shell.execute_reply.started":"2025-10-22T16:18:35.166579Z","shell.execute_reply":"2025-10-22T16:18:36.108521Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Use this for the regression and the ffnn (give it to chatgpt with the 4 blocks)\n## tell him to refer to the 4 blocks to calculate the below items\n\n\n# --- Evaluation for linear regression ---\n# mae = mean_absolute_error(y_test, y_pred_lr)\n# mse = mean_squared_error(y_test, y_pred_lr)\n# rmse = np.sqrt(mse)\n# r2 = r2_score(y_test, y_pred_lr)\n\n# print(\"ðŸ“Š Linear Regression Results:\")\n# print(f\"MAE:  {mae:.3f}\")\n# print(f\"MSE:  {mse:.3f}\")\n# print(f\"RMSE: {rmse:.3f}\")\n# print(f\"RÂ²:   {r2:.3f}\")\n\n\n\n# # --- Evaluation for FFNN ---\n# mae_nn = mean_absolute_error(y_test, y_pred_nn)\n# mse_nn = mean_squared_error(y_test, y_pred_nn)\n# rmse_nn = np.sqrt(mse_nn)\n# r2_nn = r2_score(y_test, y_pred_nn)\n\n# print(\"\\nðŸ¤– FFNN Results:\")\n# print(f\"MAE:  {mae_nn:.3f}\")\n# print(f\"MSE:  {mse_nn:.3f}\")\n# print(f\"RMSE: {rmse_nn:.3f}\")\n# print(f\"RÂ²:   {r2_nn:.3f}\")\n\n\n# ==========================\n# âœ… BLOCK 5: Model Evaluation\n# ==========================\n\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\n# ---- Predictions ----\ny_pred_lr = lr.predict(X_test_s)\ny_pred_nn = ffnn.predict(X_test_s).reshape(-1)\n\n# --- Evaluation for Linear Regression ---\nmae = mean_absolute_error(y_test, y_pred_lr)\nmse = mean_squared_error(y_test, y_pred_lr)\nrmse = np.sqrt(mse)\nr2 = r2_score(y_test, y_pred_lr)\n\nprint(\"ðŸ“Š Linear Regression Results:\")\nprint(f\"MAE:  {mae:.3f}\")\nprint(f\"MSE:  {mse:.3f}\")\nprint(f\"RMSE: {rmse:.3f}\")\nprint(f\"RÂ²:   {r2:.3f}\")\n\n# --- Evaluation for FFNN ---\nmae_nn = mean_absolute_error(y_test, y_pred_nn)\nmse_nn = mean_squared_error(y_test, y_pred_nn)\nrmse_nn = np.sqrt(mse_nn)\nr2_nn = r2_score(y_test, y_pred_nn)\n\nprint(\"\\nðŸ¤– FFNN Results:\")\nprint(f\"MAE:  {mae_nn:.3f}\")\nprint(f\"MSE:  {mse_nn:.3f}\")\nprint(f\"RMSE: {rmse_nn:.3f}\")\nprint(f\"RÂ²:   {r2_nn:.3f}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:18:36.110815Z","iopub.execute_input":"2025-10-22T16:18:36.111155Z","iopub.status.idle":"2025-10-22T16:18:37.096419Z","shell.execute_reply.started":"2025-10-22T16:18:36.111129Z","shell.execute_reply":"2025-10-22T16:18:37.09532Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Diagrams to be pltted based on the data values.\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nresults = pd.DataFrame({\n    \"Model\": [\"Linear Regression\", \"FFNN\"],\n    \"MAE\": [mae, mae_nn],\n    \"MSE\": [mse, mse_nn],\n    \"RMSE\": [rmse, rmse_nn],\n    \"RÂ²\": [r2, r2_nn]\n})\n\nplt.figure(figsize=(8,5))\nsns.barplot(data=results.melt(id_vars=\"Model\", var_name=\"Metric\", value_name=\"Value\"),\n            x=\"Metric\", y=\"Value\", hue=\"Model\", palette=\"viridis\")\nplt.title(\"Model Performance Comparison (Predicting Upcoming Total Points)\")\nplt.tight_layout()\nplt.show()\n\nresults\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:18:37.097469Z","iopub.execute_input":"2025-10-22T16:18:37.097734Z","iopub.status.idle":"2025-10-22T16:18:37.342012Z","shell.execute_reply.started":"2025-10-22T16:18:37.097714Z","shell.execute_reply":"2025-10-22T16:18:37.340689Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model and SHAP/LIME\n#### These are the 4 blocks to be shifted","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}